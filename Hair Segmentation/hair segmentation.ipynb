{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WorkingA_3ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvGEv9EvzSqJ"
      },
      "source": [
        "# Assignment 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aheN4H9Yo0Q"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6rEtFIUzmeE"
      },
      "source": [
        "# Mount the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbzllmSmYrET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "a60ea8f1-17b5-48d4-8ca8-99d4db90bb43"
      },
      "source": [
        "# mount the drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n",
        "# Go to the assignment folder in the drive and make it current location\n",
        "%cd /gdrive/My Drive/Assignment 3\n",
        "print('\\n\\nFiles in the Assignment 3 Data folder:')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-58032aed92e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount the drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Go to the assignment folder in the drive and make it current location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTHgbydL0NUW"
      },
      "source": [
        "# Load images, then parse the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLwtID76Yt4Y"
      },
      "source": [
        "IMAGE_PATH = 'images/images/'\n",
        "# create list of PATHS\n",
        "image_paths_full = [os.path.join(IMAGE_PATH, x) for x in os.listdir(IMAGE_PATH) if x.endswith('.jpg')]\n",
        "\n",
        "DATASET_FULL_SIZE = len(image_paths_full)\n",
        "print(image_paths_full)\n",
        "print(DATASET_FULL_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV_wWM45YyAK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_valid_image_paths, test_image_paths = train_test_split(image_paths_full, test_size=0.15, random_state=42)\n",
        "\n",
        "train_image_paths, valid_image_paths = train_test_split(image_paths_full, test_size=0.15, random_state=42)\n",
        "\n",
        "TRAIN_DATASET_SIZE = len(train_image_paths)\n",
        "VALID_DATASET_SIZE = len(valid_image_paths)\n",
        "TEST_DATASET_SIZE = len(test_image_paths)\n",
        "\n",
        "print(TRAIN_DATASET_SIZE)\n",
        "print(VALID_DATASET_SIZE)\n",
        "print(TEST_DATASET_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCWqe5vwY486"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "IMG_SIZE = 128\n",
        "np.random.seed(0)\n",
        "\n",
        "# parse_data function helps to get each image and the corresponding mask,\n",
        "#                              performs decoding, resizing, rescaling, and other data transformations\n",
        "# for more data transformations: https://github.com/HasnainRaz/SemSegPipeline/blob/master/dataloader.py\n",
        "\n",
        "def parse_data(image_path):\n",
        "  image_content = tf.io.read_file(image_path)\n",
        " \n",
        "  mask_path = tf.strings.regex_replace(image_path, \"images\", \"masks\")\n",
        "  mask_path = tf.strings.regex_replace(mask_path, \"jpg\", \"jpg\")\n",
        "  mask_content = tf.io.read_file(mask_path)\n",
        "  \n",
        "  image = tf.image.decode_jpeg(image_content, channels=3)\n",
        "  mask = tf.image.decode_jpeg(mask_content, channels=1)\n",
        "  \n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "  mask = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
        "  mask = tf.cast(mask, tf.float32) /255.0\n",
        "  \n",
        "  # The pixels in the given segmentation mask are labeled either {1, 2, 3}. \n",
        "  # So we subtract 1 from the segmentation mask, resulting in labels that are : {0, 1, 2}.\n",
        "  # mask -= 1 \n",
        "  #mask = tf.image.convert_image_dtype(mask, tf.uint8)\n",
        "  \n",
        "  image = tf.convert_to_tensor(image)\n",
        "  mask = tf.convert_to_tensor(mask)\n",
        "\n",
        "  return image, mask\n",
        "\n",
        "# Use Dataset.map to apply a function to each element of the dataset\n",
        "train_dataset_imgpaths = tf.data.Dataset.from_tensor_slices((train_image_paths))\n",
        "train_dataset = train_dataset_imgpaths.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "valid_dataset_imgpaths = tf.data.Dataset.from_tensor_slices((valid_image_paths))\n",
        "valid_dataset = valid_dataset_imgpaths.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "test_dataset_imgpaths = tf.data.Dataset.from_tensor_slices((test_image_paths))\n",
        "test_dataset = test_dataset_imgpaths.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOrXLN19Y_35"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_dataset_batch = train_dataset.cache().shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n",
        "train_dataset_batch = train_dataset_batch.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "valid_dataset_batch = valid_dataset.cache().repeat().batch(BATCH_SIZE)\n",
        "valid_dataset_batch = valid_dataset_batch.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_dataset_batch = test_dataset.cache().repeat().batch(BATCH_SIZE)\n",
        "test_dataset_batch = test_dataset_batch.prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryYp60s7yx9I"
      },
      "source": [
        "# Importing Testing Images for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruxL-sYQ8Cy6"
      },
      "source": [
        "TESTING_PATH = 'testing_images/'\n",
        "test_paths_full = [os.path.join(TESTING_PATH,x) for x in os.listdir(TESTING_PATH) if x.endswith('.jpg')]\n",
        "\n",
        "TESTING_FULL_SIZE = len(test_paths_full)\n",
        "print(test_paths_full)\n",
        "print(TESTING_FULL_SIZE)\n",
        "\n",
        "def parse_test_data(image_path):\n",
        "  image_content = tf.io.read_file(image_path)\n",
        "  test_image = tf.image.decode_jpeg(image_content, channels= 3)\n",
        "  test_image = tf.image.resize(test_image, (IMG_SIZE, IMG_SIZE))\n",
        "  test_image = tf.cast(test_image, tf.float32) / 255.0\n",
        "  test_image = tf.convert_to_tensor(test_image)\n",
        "  return test_image\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_paths_full))\n",
        "testing_content = test_data.map(parse_test_data, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "testing_dataset_batch = testing_content.cache().batch(BATCH_SIZE)\n",
        "testing_dataset_batch = testing_dataset_batch.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# print(testing_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nerT1lY2VQhu"
      },
      "source": [
        "print(testing_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugTTPGyu0Vzj"
      },
      "source": [
        "# Display a sample image from training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x_UA-wCZCFQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# np.random.seed()\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "  plt.show()\n",
        "\n",
        "for image, mask in train_dataset.take(1):\n",
        "  sample_image, sample_mask = image, mask\n",
        "  print('Sample Images')\n",
        "  display([sample_image, sample_mask])\n",
        "print(sample_mask.shape)\n",
        "print(sample_image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mITCEGCY0ckJ"
      },
      "source": [
        "# Create a U-net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4Ka8XW1ZDko"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Build U-Net model\n",
        "s = Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "c1 = Conv2D(16, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "# c1 = Conv2D(16, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "# c4 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "# c4 = Dropout(0.2) (c4)\n",
        "# c4 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "# c5 = Dropout(0.3) (c5)\n",
        "# c5 = Conv2D(256, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "# c5 = Dropout(0.3) (c5)\n",
        "# c5 = Conv2D(256, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "# c6 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "# c6 = Dropout(0.2) (c6)\n",
        "# c6 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "# c9 = Conv2D(16, (5, 5), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(3, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[s], outputs=[outputs])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJUseRhSZyO0"
      },
      "source": [
        "model.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvsjEpc_ZJIf"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=2):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJx_T75sy8SE"
      },
      "source": [
        "# Model Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3lqNbkuZJpH"
      },
      "source": [
        "EPOCHS = 35\n",
        "VAL_SUBSPLITS = 5\n",
        "STEPS_PER_EPOCH = TRAIN_DATASET_SIZE//BATCH_SIZE\n",
        "VALIDATION_STEPS = VALID_DATASET_SIZE//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset_batch, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=valid_dataset_batch,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwPxAMNyZHju"
      },
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 5])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YC7WTNhaFTA"
      },
      "source": [
        "show_predictions(test_dataset_batch, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFsU4pflyrc-"
      },
      "source": [
        "# Testing Image Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87UHaYoDqeTE"
      },
      "source": [
        "results = model.predict(testing_dataset_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqY3p1GpcDnE"
      },
      "source": [
        "print(results.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v8jiHXwC-XM"
      },
      "source": [
        "results = tf.image.resize(results, (250, 250))\n",
        "results = tf.image.rgb_to_grayscale(results)\n",
        "for i in range (3):  \n",
        "  plt.imshow(tf.keras.preprocessing.image.array_to_img(results[i]))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OOUaj7jyFcr"
      },
      "source": [
        "# Preparing folder to save predicted testing images masks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBQNlAO1xJyW"
      },
      "source": [
        "# Making sure the google drive pred_mask folder is empty before new data is written to ONLY keep files that is needed. \n",
        "import os, shutil\n",
        "def empty_folder():\n",
        "  folder = 'pred_mask/'\n",
        "  for filename in os.listdir(folder):\n",
        "      file_path = os.path.join(folder, filename)\n",
        "      try:\n",
        "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "              os.unlink(file_path)\n",
        "          elif os.path.isdir(file_path):\n",
        "              shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "  print('Delete Complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N4zr2Uf0-eF"
      },
      "source": [
        "# Save the images to pred_mask folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95XEJ1q0dBcF"
      },
      "source": [
        "test_paths_full = tf.strings.substr(test_paths_full, 24,-5)\n",
        "test_paths_full = tf.strings.regex_replace(test_paths_full,'.jpg','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6liTvH9ZC6EW"
      },
      "source": [
        "# Empty the google drive folder of any past masks and random masks/images\n",
        "empty_folder()\n",
        "\n",
        "# Saving the images to the pred_mask folder in google drive\n",
        "for i in range(len(results)):\n",
        "  tf.keras.preprocessing.image.save_img('./pred_mask/{}'.format(test_paths_full[i]),results[i], file_format='jpeg')\n",
        "  # tf.io.write_file('pred_mask/',results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "212C5CyKYE9P"
      },
      "source": [
        "# Renaming the files to get rid of the \"b'\" before the file names. Since Tf.strings modification returns it with b' before a string. \n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print('waiting for sleep timer...')\n",
        "for i in tqdm(range(60)):\n",
        "  time.sleep(.1)\n",
        "\n",
        "print('Re-naming files')\n",
        "collection = \"pred_mask/\"\n",
        "for i, filename in tqdm(enumerate(os.listdir(collection))):\n",
        "  time.sleep(.1)\n",
        "  newName = filename[2:-1]\n",
        "  # print(newName)\n",
        "  # print(collection + 'test_mask_' + newName + '.jpg')\n",
        "  os.rename(collection + filename, collection + 'test_mask_' + newName+ '.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3qANkeb9rr_"
      },
      "source": [
        "# Creating a csv file based on the mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCUuPjm6s_RH"
      },
      "source": [
        "import pandas as pd\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import sys\n",
        "%matplotlib inline\n",
        "\n",
        "# encoding function\n",
        "# based on the implementation: https://www.kaggle.com/rakhlin/fast-run-length-encoding-python/code\n",
        "def rle_encoding(x):\n",
        "  '''x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
        "  Returns run length as list\n",
        "  '''\n",
        "  dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n",
        "  run_lengths = []\n",
        "  prev = -2\n",
        "  for b in dots:\n",
        "    if (b>prev+1): run_lengths.extend((b+1, 1))\n",
        "    run_lengths[-1] += 1\n",
        "    prev = b\n",
        "  return run_lengths\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import datetime\n",
        "\n",
        "# (* update) the input_path using your folder path\n",
        "input_path = 'pred_mask/'\n",
        "\n",
        "# get a sorted list of all mask filenames in the folder\n",
        "masks = [f for f in os.listdir(input_path) if f.endswith('.jpg')]\n",
        "masks = sorted(masks, key=lambda s:int(s.split('_')[2].split('.')[0]))\n",
        "\n",
        "# encode all masks\n",
        "encodings = []\n",
        "for i, file in tqdm(enumerate(masks), total=len(masks)):\n",
        "  mask = imread(os.path.join(input_path, file))\n",
        "  #img_size =10\n",
        "  #mask = resize(mask, (img_size, img_size), mode='constant', preserve_range=True)\n",
        "  mask = np.array(mask, dtype=np.uint8)\n",
        "  mask = np.round(mask/255)\n",
        "  encodings.append(rle_encoding(mask))\n",
        "\n",
        "# (** update) the path where to save the submission csv file\n",
        "sub = pd.DataFrame()\n",
        "sub['ImageId'] = pd.Series(masks).apply(lambda x: os.path.splitext(x)[0])\n",
        "sub['EncodedPixels'] = pd.Series(encodings).apply(lambda x: ' '.join(str(y) for y in x))\n",
        "sub.to_csv(os.path.join('submission/', 'test_mask_preds_'+datetime.datetime.now().strftime(\"%H%M%S\")+'.csv'), index=False)\n",
        "sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}