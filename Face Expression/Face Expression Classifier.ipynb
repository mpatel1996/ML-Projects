{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11BMqTHB0Mw"
      },
      "source": [
        "**Assignment 2**\n",
        "\n",
        "*CNN for Facial Expression classification*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvsvK323Fp1J"
      },
      "source": [
        "# Importing needed libraries and modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adadelta, Adam\n",
        "from keras.constraints import maxnorm\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomContrast,RandomZoom,Resizing,RandomTranslation\n",
        "from keras.utils import np_utils\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsfGB6M-yyv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c295517-25ce-4ec9-e303-0f6e72abcf05"
      },
      "source": [
        "# mount the drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n",
        "# Go to the assignment folder in the drive and make it current location\n",
        "%cd /gdrive/My\\ Drive/Assignment_2_data\n",
        "print('Files in the Assignment 2 Data folder: ')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n",
            "/gdrive/My Drive/Assignment_2_data\n",
            "Files in the Assignment 2 Data folder: \n",
            "best-model.h5  submission.csv  test_data.csv  train_data.csv  train_target.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KT655Z8RFcm"
      },
      "source": [
        "# loading the data \n",
        "X_train = np.array(pd.read_csv('train_data.csv', header=None))\n",
        "X_test = np.array(pd.read_csv('test_data.csv',header=None))\n",
        "Y_train = np.array(pd.read_csv('train_target.csv',header=None))\n",
        "\n",
        "# Reshape the np array\n",
        "X_train = X_train.reshape(-1,48,48)\n",
        "X_test = X_test.reshape(-1,48,48)\n",
        "\n",
        "# #normalize the inputs from 0-255 to 0-1\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "\n",
        "# Making sure everything is same dims\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "\n",
        "# print(X_train.shape,X_test.shape,Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDM9OvU23fkH"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train,x_test,Y_train,Y_test = train_test_split(X_train,Y_train,test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EcsfSEBJkxT"
      },
      "source": [
        "# One hot coding \n",
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "Y_train = lb.fit_transform(Y_train)\n",
        "class_num = Y_train.shape[1]\n",
        "# print(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AevhzqWNOQ"
      },
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding data augmentation\n",
        "model.add(RandomContrast([0.5,1.5]))\n",
        "model.add(RandomFlip('horizontal_and_vertical'))\n",
        "model.add(RandomRotation([0.5,1.5]))\n",
        "model.add(Resizing(128,128,interpolation='bicubic'))\n",
        "model.add(RandomZoom([0.2,0.5]))\n",
        "model.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
        "\n",
        "#first convolutional layer\n",
        "model.add(Conv2D(32, (5,5), input_shape=(48,48,1), activation='relu', padding='same'))\n",
        "# model.add(Conv2D(32, (5,5), input_shape=(48,48,1), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#second convolutional layer\n",
        "model.add(Conv2D(64,(5,5), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64,(5,5), activation='relu', padding='same'))\n",
        "# model.add(Conv2D(64,(5,5), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#third later \n",
        "model.add(Conv2D(128, (5,5), activation='relu', padding='same'))\n",
        "# model.add(Conv2D(128, (5,5), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# fourth later \n",
        "model.add(Conv2D(256, (5,5), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (5,5), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Fifth Layer \n",
        "model.add(Conv2D(512, (5,5), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128, kernel_regularizer=l2(0.001),kernel_constraint=maxnorm(class_num)))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "model.add(Dense(32, kernel_regularizer=l2(0.001), kernel_constraint=maxnorm(class_num)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(class_num))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPVa39dWYuRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac8d653-54ab-46c8-a090-c59692e82769"
      },
      "source": [
        "# np.random.seed(95)\n",
        "\n",
        "# saving the model for later. Used in model checkpoint\n",
        "bestModel = \"best-model.h5\"\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "mc = ModelCheckpoint(bestModel, monitor='val_accuracy', save_freq='epoch', mode='max', save_best_only=True)\n",
        "hist = model.fit(X_train, Y_train, validation_split= 0.1, epochs=300,batch_size=82, verbose=1, callbacks=[mc])\n",
        "\n",
        "# Print out the highest accuracy we hit for the best model checkpoint\n",
        "val = hist.history['val_accuracy']\n",
        "print(\"Max Accuracy: \", np.max(val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/178 [..............................] - ETA: 11s - loss: 2.2363 - accuracy: 0.4146WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0490s vs `on_train_batch_end` time: 0.0748s). Check your callbacks.\n",
            "178/178 [==============================] - 25s 139ms/step - loss: 1.3912 - accuracy: 0.4318 - val_loss: 1.2949 - val_accuracy: 0.4481\n",
            "Epoch 2/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.2428 - accuracy: 0.4443 - val_loss: 1.1920 - val_accuracy: 0.4481\n",
            "Epoch 3/300\n",
            "178/178 [==============================] - 24s 137ms/step - loss: 1.1610 - accuracy: 0.4456 - val_loss: 1.1323 - val_accuracy: 0.4481\n",
            "Epoch 4/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.1201 - accuracy: 0.4458 - val_loss: 1.1014 - val_accuracy: 0.4481\n",
            "Epoch 5/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0982 - accuracy: 0.4454 - val_loss: 1.0921 - val_accuracy: 0.4481\n",
            "Epoch 6/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.0858 - accuracy: 0.4457 - val_loss: 1.0819 - val_accuracy: 0.4481\n",
            "Epoch 7/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.0787 - accuracy: 0.4458 - val_loss: 1.0740 - val_accuracy: 0.4481\n",
            "Epoch 8/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0741 - accuracy: 0.4455 - val_loss: 1.0787 - val_accuracy: 0.4481\n",
            "Epoch 9/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0728 - accuracy: 0.4460 - val_loss: 1.0763 - val_accuracy: 0.4481\n",
            "Epoch 10/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.0750 - accuracy: 0.4461 - val_loss: 1.0878 - val_accuracy: 0.4481\n",
            "Epoch 11/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.0739 - accuracy: 0.4455 - val_loss: 1.0773 - val_accuracy: 0.4481\n",
            "Epoch 12/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 1.0711 - accuracy: 0.4477 - val_loss: 1.0709 - val_accuracy: 0.4481\n",
            "Epoch 13/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 1.0643 - accuracy: 0.4495 - val_loss: 1.0788 - val_accuracy: 0.4475\n",
            "Epoch 14/300\n",
            "178/178 [==============================] - 25s 140ms/step - loss: 1.0666 - accuracy: 0.4511 - val_loss: 1.0728 - val_accuracy: 0.4524\n",
            "Epoch 15/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 1.0651 - accuracy: 0.4481 - val_loss: 1.0914 - val_accuracy: 0.4271\n",
            "Epoch 16/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 1.0753 - accuracy: 0.4458 - val_loss: 1.0741 - val_accuracy: 0.4475\n",
            "Epoch 17/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0625 - accuracy: 0.4520 - val_loss: 1.1036 - val_accuracy: 0.4468\n",
            "Epoch 18/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0556 - accuracy: 0.4559 - val_loss: 1.0790 - val_accuracy: 0.4425\n",
            "Epoch 19/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0550 - accuracy: 0.4559 - val_loss: 1.0652 - val_accuracy: 0.4499\n",
            "Epoch 20/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 1.0480 - accuracy: 0.4628 - val_loss: 1.1047 - val_accuracy: 0.3127\n",
            "Epoch 21/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 1.0222 - accuracy: 0.4822 - val_loss: 1.0844 - val_accuracy: 0.4574\n",
            "Epoch 22/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.9797 - accuracy: 0.5172 - val_loss: 1.1109 - val_accuracy: 0.3918\n",
            "Epoch 23/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.9283 - accuracy: 0.5633 - val_loss: 1.0372 - val_accuracy: 0.5025\n",
            "Epoch 24/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.8912 - accuracy: 0.5865 - val_loss: 0.9733 - val_accuracy: 0.5470\n",
            "Epoch 25/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.8389 - accuracy: 0.6211 - val_loss: 0.9699 - val_accuracy: 0.5513\n",
            "Epoch 26/300\n",
            "178/178 [==============================] - 25s 139ms/step - loss: 0.8001 - accuracy: 0.6450 - val_loss: 0.8523 - val_accuracy: 0.6279\n",
            "Epoch 27/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.7709 - accuracy: 0.6604 - val_loss: 0.8620 - val_accuracy: 0.5915\n",
            "Epoch 28/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.7489 - accuracy: 0.6749 - val_loss: 0.8523 - val_accuracy: 0.6156\n",
            "Epoch 29/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.7281 - accuracy: 0.6903 - val_loss: 0.8475 - val_accuracy: 0.6316\n",
            "Epoch 30/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.7063 - accuracy: 0.7025 - val_loss: 0.9358 - val_accuracy: 0.5637\n",
            "Epoch 31/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.6979 - accuracy: 0.7077 - val_loss: 0.9457 - val_accuracy: 0.5470\n",
            "Epoch 32/300\n",
            "178/178 [==============================] - 24s 138ms/step - loss: 0.6845 - accuracy: 0.7186 - val_loss: 0.7788 - val_accuracy: 0.6632\n",
            "Epoch 33/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.6734 - accuracy: 0.7144 - val_loss: 0.7659 - val_accuracy: 0.6638\n",
            "Epoch 34/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.6593 - accuracy: 0.7295 - val_loss: 0.7182 - val_accuracy: 0.6959\n",
            "Epoch 35/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.6528 - accuracy: 0.7361 - val_loss: 0.8181 - val_accuracy: 0.6174\n",
            "Epoch 36/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.6488 - accuracy: 0.7327 - val_loss: 0.7135 - val_accuracy: 0.6873\n",
            "Epoch 37/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.6389 - accuracy: 0.7392 - val_loss: 0.7590 - val_accuracy: 0.6780\n",
            "Epoch 38/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.6273 - accuracy: 0.7451 - val_loss: 0.7943 - val_accuracy: 0.6539\n",
            "Epoch 39/300\n",
            "178/178 [==============================] - 24s 138ms/step - loss: 0.6195 - accuracy: 0.7543 - val_loss: 0.6569 - val_accuracy: 0.7336\n",
            "Epoch 40/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.6049 - accuracy: 0.7547 - val_loss: 0.7486 - val_accuracy: 0.6743\n",
            "Epoch 41/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5971 - accuracy: 0.7571 - val_loss: 0.6832 - val_accuracy: 0.7052\n",
            "Epoch 42/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5949 - accuracy: 0.7607 - val_loss: 0.6604 - val_accuracy: 0.7274\n",
            "Epoch 43/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5896 - accuracy: 0.7636 - val_loss: 0.8088 - val_accuracy: 0.6489\n",
            "Epoch 44/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5845 - accuracy: 0.7655 - val_loss: 0.7590 - val_accuracy: 0.6737\n",
            "Epoch 45/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5686 - accuracy: 0.7693 - val_loss: 0.7008 - val_accuracy: 0.7015\n",
            "Epoch 46/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5702 - accuracy: 0.7765 - val_loss: 0.7027 - val_accuracy: 0.7114\n",
            "Epoch 47/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5706 - accuracy: 0.7721 - val_loss: 0.6919 - val_accuracy: 0.7015\n",
            "Epoch 48/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5652 - accuracy: 0.7755 - val_loss: 0.6977 - val_accuracy: 0.7138\n",
            "Epoch 49/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5633 - accuracy: 0.7750 - val_loss: 0.6782 - val_accuracy: 0.7281\n",
            "Epoch 50/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5459 - accuracy: 0.7824 - val_loss: 0.6817 - val_accuracy: 0.7095\n",
            "Epoch 51/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.5535 - accuracy: 0.7811 - val_loss: 0.7190 - val_accuracy: 0.7052\n",
            "Epoch 52/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5514 - accuracy: 0.7856 - val_loss: 0.6373 - val_accuracy: 0.7330\n",
            "Epoch 53/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5453 - accuracy: 0.7869 - val_loss: 0.6764 - val_accuracy: 0.7169\n",
            "Epoch 54/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5426 - accuracy: 0.7905 - val_loss: 0.6844 - val_accuracy: 0.7145\n",
            "Epoch 55/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5348 - accuracy: 0.7933 - val_loss: 0.8273 - val_accuracy: 0.6663\n",
            "Epoch 56/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.5342 - accuracy: 0.7924 - val_loss: 0.7318 - val_accuracy: 0.6712\n",
            "Epoch 57/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.5343 - accuracy: 0.7890 - val_loss: 0.7945 - val_accuracy: 0.6768\n",
            "Epoch 58/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.5238 - accuracy: 0.7958 - val_loss: 0.6540 - val_accuracy: 0.7305\n",
            "Epoch 59/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.5268 - accuracy: 0.7957 - val_loss: 0.7753 - val_accuracy: 0.6644\n",
            "Epoch 60/300\n",
            "178/178 [==============================] - 24s 137ms/step - loss: 0.5299 - accuracy: 0.7989 - val_loss: 0.6107 - val_accuracy: 0.7441\n",
            "Epoch 61/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.5229 - accuracy: 0.7969 - val_loss: 0.6767 - val_accuracy: 0.7188\n",
            "Epoch 62/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5202 - accuracy: 0.8020 - val_loss: 0.6876 - val_accuracy: 0.7033\n",
            "Epoch 63/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.5128 - accuracy: 0.8031 - val_loss: 0.6026 - val_accuracy: 0.7553\n",
            "Epoch 64/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5134 - accuracy: 0.8027 - val_loss: 0.6239 - val_accuracy: 0.7429\n",
            "Epoch 65/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5143 - accuracy: 0.8041 - val_loss: 0.6757 - val_accuracy: 0.7188\n",
            "Epoch 66/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5068 - accuracy: 0.8050 - val_loss: 0.6221 - val_accuracy: 0.7417\n",
            "Epoch 67/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5182 - accuracy: 0.8027 - val_loss: 0.6313 - val_accuracy: 0.7355\n",
            "Epoch 68/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5094 - accuracy: 0.8066 - val_loss: 0.6266 - val_accuracy: 0.7460\n",
            "Epoch 69/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5043 - accuracy: 0.8119 - val_loss: 0.6511 - val_accuracy: 0.7423\n",
            "Epoch 70/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.5019 - accuracy: 0.8098 - val_loss: 0.5857 - val_accuracy: 0.7590\n",
            "Epoch 71/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.5046 - accuracy: 0.8077 - val_loss: 0.6812 - val_accuracy: 0.7293\n",
            "Epoch 72/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4955 - accuracy: 0.8132 - val_loss: 0.7737 - val_accuracy: 0.6799\n",
            "Epoch 73/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4968 - accuracy: 0.8138 - val_loss: 0.6186 - val_accuracy: 0.7429\n",
            "Epoch 74/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4973 - accuracy: 0.8096 - val_loss: 0.6498 - val_accuracy: 0.7256\n",
            "Epoch 75/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.4892 - accuracy: 0.8148 - val_loss: 0.6239 - val_accuracy: 0.7299\n",
            "Epoch 76/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.4874 - accuracy: 0.8160 - val_loss: 0.6317 - val_accuracy: 0.7330\n",
            "Epoch 77/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4919 - accuracy: 0.8168 - val_loss: 0.6049 - val_accuracy: 0.7447\n",
            "Epoch 78/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4851 - accuracy: 0.8157 - val_loss: 0.6311 - val_accuracy: 0.7454\n",
            "Epoch 79/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4820 - accuracy: 0.8174 - val_loss: 0.5977 - val_accuracy: 0.7565\n",
            "Epoch 80/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4847 - accuracy: 0.8156 - val_loss: 0.6754 - val_accuracy: 0.7287\n",
            "Epoch 81/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.4738 - accuracy: 0.8222 - val_loss: 0.6556 - val_accuracy: 0.7478\n",
            "Epoch 82/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.4833 - accuracy: 0.8191 - val_loss: 0.5981 - val_accuracy: 0.7602\n",
            "Epoch 83/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4758 - accuracy: 0.8201 - val_loss: 0.6214 - val_accuracy: 0.7460\n",
            "Epoch 84/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4796 - accuracy: 0.8151 - val_loss: 0.6087 - val_accuracy: 0.7472\n",
            "Epoch 85/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.4767 - accuracy: 0.8196 - val_loss: 0.8114 - val_accuracy: 0.7095\n",
            "Epoch 86/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4687 - accuracy: 0.8252 - val_loss: 0.6520 - val_accuracy: 0.7404\n",
            "Epoch 87/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.4704 - accuracy: 0.8232 - val_loss: 0.5889 - val_accuracy: 0.7689\n",
            "Epoch 88/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4720 - accuracy: 0.8183 - val_loss: 0.6241 - val_accuracy: 0.7522\n",
            "Epoch 89/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4610 - accuracy: 0.8276 - val_loss: 0.6209 - val_accuracy: 0.7503\n",
            "Epoch 90/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4655 - accuracy: 0.8237 - val_loss: 0.5940 - val_accuracy: 0.7627\n",
            "Epoch 91/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4640 - accuracy: 0.8237 - val_loss: 0.5971 - val_accuracy: 0.7478\n",
            "Epoch 92/300\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 0.4646 - accuracy: 0.8298 - val_loss: 0.6693 - val_accuracy: 0.7478\n",
            "Epoch 93/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4647 - accuracy: 0.8275 - val_loss: 0.6262 - val_accuracy: 0.7565\n",
            "Epoch 94/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4550 - accuracy: 0.8290 - val_loss: 0.6193 - val_accuracy: 0.7571\n",
            "Epoch 95/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4658 - accuracy: 0.8237 - val_loss: 0.6573 - val_accuracy: 0.7410\n",
            "Epoch 96/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4550 - accuracy: 0.8292 - val_loss: 0.6197 - val_accuracy: 0.7664\n",
            "Epoch 97/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4578 - accuracy: 0.8309 - val_loss: 0.6975 - val_accuracy: 0.7188\n",
            "Epoch 98/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4547 - accuracy: 0.8315 - val_loss: 0.6033 - val_accuracy: 0.7509\n",
            "Epoch 99/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4493 - accuracy: 0.8313 - val_loss: 0.6454 - val_accuracy: 0.7540\n",
            "Epoch 100/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4554 - accuracy: 0.8313 - val_loss: 0.5708 - val_accuracy: 0.7614\n",
            "Epoch 101/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.4540 - accuracy: 0.8316 - val_loss: 0.5748 - val_accuracy: 0.7732\n",
            "Epoch 102/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4469 - accuracy: 0.8302 - val_loss: 0.6504 - val_accuracy: 0.7491\n",
            "Epoch 103/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4447 - accuracy: 0.8361 - val_loss: 0.5850 - val_accuracy: 0.7682\n",
            "Epoch 104/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4489 - accuracy: 0.8318 - val_loss: 0.6475 - val_accuracy: 0.7330\n",
            "Epoch 105/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4495 - accuracy: 0.8327 - val_loss: 0.5791 - val_accuracy: 0.7707\n",
            "Epoch 106/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.4404 - accuracy: 0.8338 - val_loss: 0.5799 - val_accuracy: 0.7763\n",
            "Epoch 107/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4355 - accuracy: 0.8396 - val_loss: 0.7598 - val_accuracy: 0.7101\n",
            "Epoch 108/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4428 - accuracy: 0.8345 - val_loss: 0.6633 - val_accuracy: 0.7349\n",
            "Epoch 109/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.4420 - accuracy: 0.8379 - val_loss: 0.5748 - val_accuracy: 0.7794\n",
            "Epoch 110/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4396 - accuracy: 0.8349 - val_loss: 0.5887 - val_accuracy: 0.7670\n",
            "Epoch 111/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4278 - accuracy: 0.8457 - val_loss: 0.5772 - val_accuracy: 0.7738\n",
            "Epoch 112/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4309 - accuracy: 0.8402 - val_loss: 0.7753 - val_accuracy: 0.6947\n",
            "Epoch 113/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4385 - accuracy: 0.8326 - val_loss: 0.6740 - val_accuracy: 0.7460\n",
            "Epoch 114/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4267 - accuracy: 0.8425 - val_loss: 0.5754 - val_accuracy: 0.7756\n",
            "Epoch 115/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4373 - accuracy: 0.8371 - val_loss: 0.5870 - val_accuracy: 0.7540\n",
            "Epoch 116/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4374 - accuracy: 0.8386 - val_loss: 0.6816 - val_accuracy: 0.7441\n",
            "Epoch 117/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4354 - accuracy: 0.8414 - val_loss: 0.6315 - val_accuracy: 0.7769\n",
            "Epoch 118/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4304 - accuracy: 0.8420 - val_loss: 0.5852 - val_accuracy: 0.7726\n",
            "Epoch 119/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4261 - accuracy: 0.8421 - val_loss: 0.7001 - val_accuracy: 0.7256\n",
            "Epoch 120/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4252 - accuracy: 0.8465 - val_loss: 0.6502 - val_accuracy: 0.7590\n",
            "Epoch 121/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4230 - accuracy: 0.8450 - val_loss: 0.6037 - val_accuracy: 0.7559\n",
            "Epoch 122/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4246 - accuracy: 0.8438 - val_loss: 0.6559 - val_accuracy: 0.7262\n",
            "Epoch 123/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4191 - accuracy: 0.8439 - val_loss: 0.5845 - val_accuracy: 0.7713\n",
            "Epoch 124/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4242 - accuracy: 0.8439 - val_loss: 0.6647 - val_accuracy: 0.7546\n",
            "Epoch 125/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4261 - accuracy: 0.8459 - val_loss: 0.6240 - val_accuracy: 0.7503\n",
            "Epoch 126/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4222 - accuracy: 0.8421 - val_loss: 0.6529 - val_accuracy: 0.7590\n",
            "Epoch 127/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4181 - accuracy: 0.8438 - val_loss: 0.6522 - val_accuracy: 0.7763\n",
            "Epoch 128/300\n",
            "178/178 [==============================] - 25s 139ms/step - loss: 0.4186 - accuracy: 0.8428 - val_loss: 0.5795 - val_accuracy: 0.7812\n",
            "Epoch 129/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4145 - accuracy: 0.8498 - val_loss: 0.6520 - val_accuracy: 0.7621\n",
            "Epoch 130/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4169 - accuracy: 0.8456 - val_loss: 0.6658 - val_accuracy: 0.7460\n",
            "Epoch 131/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4179 - accuracy: 0.8446 - val_loss: 0.6424 - val_accuracy: 0.7497\n",
            "Epoch 132/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4130 - accuracy: 0.8476 - val_loss: 0.6660 - val_accuracy: 0.7466\n",
            "Epoch 133/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4129 - accuracy: 0.8460 - val_loss: 0.6407 - val_accuracy: 0.7379\n",
            "Epoch 134/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4100 - accuracy: 0.8481 - val_loss: 0.7316 - val_accuracy: 0.7324\n",
            "Epoch 135/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4116 - accuracy: 0.8484 - val_loss: 0.6491 - val_accuracy: 0.7522\n",
            "Epoch 136/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.4037 - accuracy: 0.8524 - val_loss: 0.5955 - val_accuracy: 0.7664\n",
            "Epoch 137/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4114 - accuracy: 0.8469 - val_loss: 0.7164 - val_accuracy: 0.7281\n",
            "Epoch 138/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4068 - accuracy: 0.8524 - val_loss: 0.7346 - val_accuracy: 0.7410\n",
            "Epoch 139/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4066 - accuracy: 0.8535 - val_loss: 0.7249 - val_accuracy: 0.7441\n",
            "Epoch 140/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4110 - accuracy: 0.8491 - val_loss: 0.6937 - val_accuracy: 0.7466\n",
            "Epoch 141/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4029 - accuracy: 0.8509 - val_loss: 0.6345 - val_accuracy: 0.7676\n",
            "Epoch 142/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3997 - accuracy: 0.8579 - val_loss: 0.6100 - val_accuracy: 0.7806\n",
            "Epoch 143/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.4043 - accuracy: 0.8533 - val_loss: 0.6403 - val_accuracy: 0.7689\n",
            "Epoch 144/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.4014 - accuracy: 0.8499 - val_loss: 0.6108 - val_accuracy: 0.7831\n",
            "Epoch 145/300\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 0.3922 - accuracy: 0.8590 - val_loss: 0.5938 - val_accuracy: 0.7837\n",
            "Epoch 146/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3968 - accuracy: 0.8568 - val_loss: 0.6146 - val_accuracy: 0.7719\n",
            "Epoch 147/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3895 - accuracy: 0.8554 - val_loss: 0.6090 - val_accuracy: 0.7553\n",
            "Epoch 148/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3936 - accuracy: 0.8576 - val_loss: 0.6609 - val_accuracy: 0.7565\n",
            "Epoch 149/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3984 - accuracy: 0.8562 - val_loss: 0.6507 - val_accuracy: 0.7627\n",
            "Epoch 150/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3971 - accuracy: 0.8553 - val_loss: 0.6186 - val_accuracy: 0.7639\n",
            "Epoch 151/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.4000 - accuracy: 0.8544 - val_loss: 0.6393 - val_accuracy: 0.7689\n",
            "Epoch 152/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3967 - accuracy: 0.8564 - val_loss: 0.6439 - val_accuracy: 0.7738\n",
            "Epoch 153/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3975 - accuracy: 0.8555 - val_loss: 0.6233 - val_accuracy: 0.7633\n",
            "Epoch 154/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3939 - accuracy: 0.8542 - val_loss: 0.6602 - val_accuracy: 0.7639\n",
            "Epoch 155/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3839 - accuracy: 0.8590 - val_loss: 0.6068 - val_accuracy: 0.7719\n",
            "Epoch 156/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3929 - accuracy: 0.8572 - val_loss: 0.6020 - val_accuracy: 0.7769\n",
            "Epoch 157/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3871 - accuracy: 0.8583 - val_loss: 0.6430 - val_accuracy: 0.7719\n",
            "Epoch 158/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3905 - accuracy: 0.8595 - val_loss: 0.6213 - val_accuracy: 0.7639\n",
            "Epoch 159/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3887 - accuracy: 0.8572 - val_loss: 0.5809 - val_accuracy: 0.7713\n",
            "Epoch 160/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3848 - accuracy: 0.8625 - val_loss: 0.6186 - val_accuracy: 0.7806\n",
            "Epoch 161/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3933 - accuracy: 0.8567 - val_loss: 0.6269 - val_accuracy: 0.7744\n",
            "Epoch 162/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3871 - accuracy: 0.8601 - val_loss: 0.6410 - val_accuracy: 0.7676\n",
            "Epoch 163/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3779 - accuracy: 0.8625 - val_loss: 0.6436 - val_accuracy: 0.7738\n",
            "Epoch 164/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3854 - accuracy: 0.8643 - val_loss: 0.6588 - val_accuracy: 0.7596\n",
            "Epoch 165/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3787 - accuracy: 0.8600 - val_loss: 0.6208 - val_accuracy: 0.7763\n",
            "Epoch 166/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3782 - accuracy: 0.8610 - val_loss: 0.6075 - val_accuracy: 0.7596\n",
            "Epoch 167/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3823 - accuracy: 0.8586 - val_loss: 0.6316 - val_accuracy: 0.7645\n",
            "Epoch 168/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3785 - accuracy: 0.8623 - val_loss: 0.5985 - val_accuracy: 0.7794\n",
            "Epoch 169/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3779 - accuracy: 0.8610 - val_loss: 0.6342 - val_accuracy: 0.7472\n",
            "Epoch 170/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3818 - accuracy: 0.8603 - val_loss: 0.5999 - val_accuracy: 0.7769\n",
            "Epoch 171/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3766 - accuracy: 0.8621 - val_loss: 0.6104 - val_accuracy: 0.7794\n",
            "Epoch 172/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3721 - accuracy: 0.8671 - val_loss: 0.5914 - val_accuracy: 0.7695\n",
            "Epoch 173/300\n",
            "178/178 [==============================] - 25s 139ms/step - loss: 0.3796 - accuracy: 0.8645 - val_loss: 0.5716 - val_accuracy: 0.7923\n",
            "Epoch 174/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3722 - accuracy: 0.8657 - val_loss: 0.6169 - val_accuracy: 0.7917\n",
            "Epoch 175/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3684 - accuracy: 0.8674 - val_loss: 0.6568 - val_accuracy: 0.7713\n",
            "Epoch 176/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3760 - accuracy: 0.8620 - val_loss: 0.7215 - val_accuracy: 0.7676\n",
            "Epoch 177/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3701 - accuracy: 0.8667 - val_loss: 0.6740 - val_accuracy: 0.7750\n",
            "Epoch 178/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3694 - accuracy: 0.8643 - val_loss: 0.6859 - val_accuracy: 0.7738\n",
            "Epoch 179/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3649 - accuracy: 0.8663 - val_loss: 0.8011 - val_accuracy: 0.7157\n",
            "Epoch 180/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3678 - accuracy: 0.8662 - val_loss: 0.6608 - val_accuracy: 0.7732\n",
            "Epoch 181/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3673 - accuracy: 0.8671 - val_loss: 0.6430 - val_accuracy: 0.7775\n",
            "Epoch 182/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3739 - accuracy: 0.8639 - val_loss: 0.6266 - val_accuracy: 0.7794\n",
            "Epoch 183/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3750 - accuracy: 0.8633 - val_loss: 0.7159 - val_accuracy: 0.7627\n",
            "Epoch 184/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3707 - accuracy: 0.8648 - val_loss: 0.6170 - val_accuracy: 0.7719\n",
            "Epoch 185/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3672 - accuracy: 0.8709 - val_loss: 0.6217 - val_accuracy: 0.7689\n",
            "Epoch 186/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3687 - accuracy: 0.8665 - val_loss: 0.6396 - val_accuracy: 0.7818\n",
            "Epoch 187/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3579 - accuracy: 0.8671 - val_loss: 0.6812 - val_accuracy: 0.7651\n",
            "Epoch 188/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3714 - accuracy: 0.8654 - val_loss: 0.6251 - val_accuracy: 0.7800\n",
            "Epoch 189/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3630 - accuracy: 0.8680 - val_loss: 0.5900 - val_accuracy: 0.7732\n",
            "Epoch 190/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3638 - accuracy: 0.8675 - val_loss: 0.6542 - val_accuracy: 0.7831\n",
            "Epoch 191/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3635 - accuracy: 0.8703 - val_loss: 0.6767 - val_accuracy: 0.7719\n",
            "Epoch 192/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3641 - accuracy: 0.8700 - val_loss: 0.6023 - val_accuracy: 0.7763\n",
            "Epoch 193/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3577 - accuracy: 0.8720 - val_loss: 0.7430 - val_accuracy: 0.7355\n",
            "Epoch 194/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3577 - accuracy: 0.8709 - val_loss: 0.6572 - val_accuracy: 0.7769\n",
            "Epoch 195/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3573 - accuracy: 0.8729 - val_loss: 0.5974 - val_accuracy: 0.7818\n",
            "Epoch 196/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3547 - accuracy: 0.8720 - val_loss: 0.6078 - val_accuracy: 0.7886\n",
            "Epoch 197/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3519 - accuracy: 0.8737 - val_loss: 0.6414 - val_accuracy: 0.7763\n",
            "Epoch 198/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3505 - accuracy: 0.8723 - val_loss: 0.7226 - val_accuracy: 0.7447\n",
            "Epoch 199/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3510 - accuracy: 0.8735 - val_loss: 0.6515 - val_accuracy: 0.7769\n",
            "Epoch 200/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3596 - accuracy: 0.8695 - val_loss: 0.6379 - val_accuracy: 0.7602\n",
            "Epoch 201/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3547 - accuracy: 0.8708 - val_loss: 0.6488 - val_accuracy: 0.7670\n",
            "Epoch 202/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3552 - accuracy: 0.8706 - val_loss: 0.6478 - val_accuracy: 0.7744\n",
            "Epoch 203/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3509 - accuracy: 0.8741 - val_loss: 0.6560 - val_accuracy: 0.7565\n",
            "Epoch 204/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3573 - accuracy: 0.8728 - val_loss: 0.5615 - val_accuracy: 0.7899\n",
            "Epoch 205/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3399 - accuracy: 0.8785 - val_loss: 0.7026 - val_accuracy: 0.7608\n",
            "Epoch 206/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3521 - accuracy: 0.8723 - val_loss: 0.6549 - val_accuracy: 0.7633\n",
            "Epoch 207/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3472 - accuracy: 0.8691 - val_loss: 0.6930 - val_accuracy: 0.7553\n",
            "Epoch 208/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3499 - accuracy: 0.8737 - val_loss: 0.6227 - val_accuracy: 0.7664\n",
            "Epoch 209/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3563 - accuracy: 0.8704 - val_loss: 0.7054 - val_accuracy: 0.7386\n",
            "Epoch 210/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3459 - accuracy: 0.8788 - val_loss: 0.6854 - val_accuracy: 0.7559\n",
            "Epoch 211/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3396 - accuracy: 0.8788 - val_loss: 0.6177 - val_accuracy: 0.7787\n",
            "Epoch 212/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3448 - accuracy: 0.8771 - val_loss: 0.6935 - val_accuracy: 0.7651\n",
            "Epoch 213/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3461 - accuracy: 0.8759 - val_loss: 0.6589 - val_accuracy: 0.7528\n",
            "Epoch 214/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3431 - accuracy: 0.8750 - val_loss: 0.6782 - val_accuracy: 0.7658\n",
            "Epoch 215/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3484 - accuracy: 0.8746 - val_loss: 0.6761 - val_accuracy: 0.7639\n",
            "Epoch 216/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3462 - accuracy: 0.8752 - val_loss: 0.6417 - val_accuracy: 0.7713\n",
            "Epoch 217/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3407 - accuracy: 0.8747 - val_loss: 0.7806 - val_accuracy: 0.7435\n",
            "Epoch 218/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3405 - accuracy: 0.8765 - val_loss: 0.6864 - val_accuracy: 0.7868\n",
            "Epoch 219/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3368 - accuracy: 0.8801 - val_loss: 0.7182 - val_accuracy: 0.7800\n",
            "Epoch 220/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3389 - accuracy: 0.8793 - val_loss: 0.6906 - val_accuracy: 0.7645\n",
            "Epoch 221/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3393 - accuracy: 0.8762 - val_loss: 0.7691 - val_accuracy: 0.7423\n",
            "Epoch 222/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3416 - accuracy: 0.8768 - val_loss: 0.6247 - val_accuracy: 0.7781\n",
            "Epoch 223/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3375 - accuracy: 0.8800 - val_loss: 0.6129 - val_accuracy: 0.7738\n",
            "Epoch 224/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3403 - accuracy: 0.8813 - val_loss: 0.7855 - val_accuracy: 0.7559\n",
            "Epoch 225/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3383 - accuracy: 0.8771 - val_loss: 0.7118 - val_accuracy: 0.7664\n",
            "Epoch 226/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3311 - accuracy: 0.8821 - val_loss: 0.6450 - val_accuracy: 0.7886\n",
            "Epoch 227/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3361 - accuracy: 0.8816 - val_loss: 0.6247 - val_accuracy: 0.7862\n",
            "Epoch 228/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3375 - accuracy: 0.8782 - val_loss: 0.6278 - val_accuracy: 0.7812\n",
            "Epoch 229/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3256 - accuracy: 0.8877 - val_loss: 0.6784 - val_accuracy: 0.7596\n",
            "Epoch 230/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3370 - accuracy: 0.8803 - val_loss: 0.6262 - val_accuracy: 0.7726\n",
            "Epoch 231/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3310 - accuracy: 0.8850 - val_loss: 0.6469 - val_accuracy: 0.7732\n",
            "Epoch 232/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3236 - accuracy: 0.8853 - val_loss: 0.6712 - val_accuracy: 0.7713\n",
            "Epoch 233/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3273 - accuracy: 0.8829 - val_loss: 0.6677 - val_accuracy: 0.7787\n",
            "Epoch 234/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3248 - accuracy: 0.8831 - val_loss: 0.6318 - val_accuracy: 0.7849\n",
            "Epoch 235/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3352 - accuracy: 0.8813 - val_loss: 0.7431 - val_accuracy: 0.7571\n",
            "Epoch 236/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3248 - accuracy: 0.8845 - val_loss: 0.6082 - val_accuracy: 0.7794\n",
            "Epoch 237/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3322 - accuracy: 0.8794 - val_loss: 0.7322 - val_accuracy: 0.7744\n",
            "Epoch 238/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3255 - accuracy: 0.8836 - val_loss: 0.6435 - val_accuracy: 0.7843\n",
            "Epoch 239/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3276 - accuracy: 0.8837 - val_loss: 0.7042 - val_accuracy: 0.7608\n",
            "Epoch 240/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3265 - accuracy: 0.8834 - val_loss: 0.6971 - val_accuracy: 0.7719\n",
            "Epoch 241/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3265 - accuracy: 0.8827 - val_loss: 0.6761 - val_accuracy: 0.7577\n",
            "Epoch 242/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3206 - accuracy: 0.8821 - val_loss: 0.6927 - val_accuracy: 0.7726\n",
            "Epoch 243/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3248 - accuracy: 0.8836 - val_loss: 0.7126 - val_accuracy: 0.7540\n",
            "Epoch 244/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3191 - accuracy: 0.8838 - val_loss: 0.6620 - val_accuracy: 0.7732\n",
            "Epoch 245/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3222 - accuracy: 0.8834 - val_loss: 0.6179 - val_accuracy: 0.7843\n",
            "Epoch 246/300\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 0.3185 - accuracy: 0.8859 - val_loss: 0.7171 - val_accuracy: 0.7800\n",
            "Epoch 247/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3299 - accuracy: 0.8793 - val_loss: 0.6836 - val_accuracy: 0.7670\n",
            "Epoch 248/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3226 - accuracy: 0.8874 - val_loss: 0.6047 - val_accuracy: 0.7818\n",
            "Epoch 249/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3180 - accuracy: 0.8876 - val_loss: 0.6820 - val_accuracy: 0.7583\n",
            "Epoch 250/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3183 - accuracy: 0.8848 - val_loss: 0.7449 - val_accuracy: 0.7695\n",
            "Epoch 251/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3200 - accuracy: 0.8827 - val_loss: 0.7614 - val_accuracy: 0.7546\n",
            "Epoch 252/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3218 - accuracy: 0.8851 - val_loss: 0.6756 - val_accuracy: 0.7849\n",
            "Epoch 253/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3176 - accuracy: 0.8875 - val_loss: 0.6206 - val_accuracy: 0.7862\n",
            "Epoch 254/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3120 - accuracy: 0.8880 - val_loss: 0.6045 - val_accuracy: 0.7923\n",
            "Epoch 255/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3188 - accuracy: 0.8877 - val_loss: 0.6947 - val_accuracy: 0.7602\n",
            "Epoch 256/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3097 - accuracy: 0.8897 - val_loss: 0.6651 - val_accuracy: 0.7874\n",
            "Epoch 257/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3218 - accuracy: 0.8858 - val_loss: 0.6399 - val_accuracy: 0.7824\n",
            "Epoch 258/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3150 - accuracy: 0.8869 - val_loss: 0.6614 - val_accuracy: 0.7769\n",
            "Epoch 259/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3189 - accuracy: 0.8880 - val_loss: 0.6058 - val_accuracy: 0.7837\n",
            "Epoch 260/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3131 - accuracy: 0.8880 - val_loss: 0.7584 - val_accuracy: 0.7726\n",
            "Epoch 261/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3213 - accuracy: 0.8881 - val_loss: 0.6092 - val_accuracy: 0.7868\n",
            "Epoch 262/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3135 - accuracy: 0.8901 - val_loss: 0.6648 - val_accuracy: 0.7726\n",
            "Epoch 263/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3132 - accuracy: 0.8913 - val_loss: 0.6880 - val_accuracy: 0.7645\n",
            "Epoch 264/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3100 - accuracy: 0.8917 - val_loss: 0.6815 - val_accuracy: 0.7781\n",
            "Epoch 265/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3141 - accuracy: 0.8849 - val_loss: 0.7248 - val_accuracy: 0.7596\n",
            "Epoch 266/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3143 - accuracy: 0.8894 - val_loss: 0.6842 - val_accuracy: 0.7763\n",
            "Epoch 267/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3117 - accuracy: 0.8861 - val_loss: 0.7084 - val_accuracy: 0.7658\n",
            "Epoch 268/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3102 - accuracy: 0.8875 - val_loss: 0.6807 - val_accuracy: 0.7676\n",
            "Epoch 269/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3173 - accuracy: 0.8887 - val_loss: 0.7178 - val_accuracy: 0.7726\n",
            "Epoch 270/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3063 - accuracy: 0.8930 - val_loss: 0.7100 - val_accuracy: 0.7763\n",
            "Epoch 271/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3054 - accuracy: 0.8919 - val_loss: 0.7080 - val_accuracy: 0.7695\n",
            "Epoch 272/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3011 - accuracy: 0.8935 - val_loss: 0.7631 - val_accuracy: 0.7546\n",
            "Epoch 273/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2967 - accuracy: 0.8924 - val_loss: 0.7473 - val_accuracy: 0.7923\n",
            "Epoch 274/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3065 - accuracy: 0.8915 - val_loss: 0.6823 - val_accuracy: 0.7726\n",
            "Epoch 275/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.2990 - accuracy: 0.8917 - val_loss: 0.6448 - val_accuracy: 0.7862\n",
            "Epoch 276/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3078 - accuracy: 0.8873 - val_loss: 0.6464 - val_accuracy: 0.7806\n",
            "Epoch 277/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.2969 - accuracy: 0.8944 - val_loss: 0.7113 - val_accuracy: 0.7596\n",
            "Epoch 278/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3073 - accuracy: 0.8901 - val_loss: 0.7633 - val_accuracy: 0.7658\n",
            "Epoch 279/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3140 - accuracy: 0.8877 - val_loss: 0.7427 - val_accuracy: 0.7695\n",
            "Epoch 280/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3002 - accuracy: 0.8952 - val_loss: 0.6982 - val_accuracy: 0.7794\n",
            "Epoch 281/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2947 - accuracy: 0.8941 - val_loss: 0.6618 - val_accuracy: 0.7892\n",
            "Epoch 282/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3033 - accuracy: 0.8930 - val_loss: 0.6856 - val_accuracy: 0.7719\n",
            "Epoch 283/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3039 - accuracy: 0.8912 - val_loss: 0.6396 - val_accuracy: 0.7837\n",
            "Epoch 284/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.2918 - accuracy: 0.8942 - val_loss: 0.7517 - val_accuracy: 0.7682\n",
            "Epoch 285/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2991 - accuracy: 0.8947 - val_loss: 0.7152 - val_accuracy: 0.7614\n",
            "Epoch 286/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.3023 - accuracy: 0.8957 - val_loss: 0.6495 - val_accuracy: 0.7800\n",
            "Epoch 287/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3011 - accuracy: 0.8920 - val_loss: 0.6757 - val_accuracy: 0.7713\n",
            "Epoch 288/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3009 - accuracy: 0.8905 - val_loss: 0.7687 - val_accuracy: 0.7726\n",
            "Epoch 289/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2979 - accuracy: 0.8970 - val_loss: 0.6920 - val_accuracy: 0.7794\n",
            "Epoch 290/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2956 - accuracy: 0.8968 - val_loss: 0.6695 - val_accuracy: 0.7886\n",
            "Epoch 291/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.3043 - accuracy: 0.8923 - val_loss: 0.6946 - val_accuracy: 0.7855\n",
            "Epoch 292/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.2965 - accuracy: 0.8963 - val_loss: 0.7400 - val_accuracy: 0.7744\n",
            "Epoch 293/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2910 - accuracy: 0.8973 - val_loss: 0.7827 - val_accuracy: 0.7849\n",
            "Epoch 294/300\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 0.2957 - accuracy: 0.8981 - val_loss: 0.6999 - val_accuracy: 0.7682\n",
            "Epoch 295/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2905 - accuracy: 0.8976 - val_loss: 0.6695 - val_accuracy: 0.7775\n",
            "Epoch 296/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2915 - accuracy: 0.8961 - val_loss: 0.6905 - val_accuracy: 0.7781\n",
            "Epoch 297/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2943 - accuracy: 0.8954 - val_loss: 0.6775 - val_accuracy: 0.7682\n",
            "Epoch 298/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2969 - accuracy: 0.8944 - val_loss: 0.6154 - val_accuracy: 0.7905\n",
            "Epoch 299/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2846 - accuracy: 0.8976 - val_loss: 0.7895 - val_accuracy: 0.7787\n",
            "Epoch 300/300\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 0.2896 - accuracy: 0.8976 - val_loss: 0.7331 - val_accuracy: 0.7775\n",
            "Max Accuracy:  0.7923362255096436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUbnO0eRNMZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2633cbd4-8c51-495f-fe7a-10866600d132"
      },
      "source": [
        "# Loading the best model we saved\n",
        "from keras.models import load_model\n",
        "bestmodel = load_model('best-model.h5')\n",
        "\n",
        "# Predicting using the saved model. \n",
        "scores = bestmodel.predict(X_test)\n",
        "# print(scores)\n",
        "\n",
        "# Getting the index of highest value and storing it into .csv file\n",
        "scores = np.argmax(scores, axis=1)\n",
        "scores = pd.Series(scores, name='Category',dtype=np.int32)\n",
        "submission = pd.concat([scores], axis=1)\n",
        "submission.to_csv(\"submission.csv\", index_label='id')\n",
        "\n",
        "# print scores to check with submission.csv if first 5 and last 5 match. \n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       0\n",
            "1       0\n",
            "2       1\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "3960    0\n",
            "3961    0\n",
            "3962    1\n",
            "3963    2\n",
            "3964    2\n",
            "Name: Category, Length: 3965, dtype: int32\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}